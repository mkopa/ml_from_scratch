{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving trivial problem using Theano\n",
    "\n",
    "## Goal\n",
    "\n",
    "In this exercise we will solve the same problem as in previous lesson but using dedicated library.\n",
    "\n",
    "Why would we want to use it? Because as our equations get larger (and we need large equations to solve difficult tasks), writing everything ourselves will become more and more difficult. In particular calculating the gradient of cost function using the approximate method might not work, even if we manage to write id down. Dedicated library like Theano can do that for huge functions with little effort and deliver precise results.\n",
    "\n",
    "Although Theano is no longer supported and slowly becomes stale, I find it better for explaining machine learning basics. So it is my conscious decision to use Theano for the purpose of this tutorial. After getting sound understanding of fundamentals it will be much easier to grasp all other frameworks. Besides, in later examples we will switch to higher-level framework (Keras) which is very much alive and can use both Theano and, much more popular today, TensorFlow libraries as backend.\n",
    "\n",
    "The most important information here is that with these libraries we represent all our operations in a symbolic way. This means that when I write:\n",
    "```\n",
    "c = a + b\n",
    "```\n",
    "and \"a\" and \"b\" are Theano variables, the \"c\" also becomes a Theano variable ant it doesn't store the result of adding \"a\" and \"b\" but represents the operation itself. Actually neither \"a\" nor \"b\" have assigned any particular number at this point. To actually calculate something I first need to compile a function that evaluates \"c\" and explicitly run it for some particular values of \"a\" and \"b\".\n",
    "\n",
    "Let's see how this will for in our trivial example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/theano/gpuarray/dnn.py:184: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to a version >= v5 and <= v7.\n",
      "  warnings.warn(\"Your cuDNN version is more recent than \"\n",
      "Using cuDNN version 7301 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 970 (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import numpy\n",
    "\n",
    "LEARNING_RATE = 0.6\n",
    "NUM_UPDATES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define two Theano variables that will store our inputs and expected outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = theano.tensor.fvector('x')\n",
    "target = theano.tensor.fscalar('target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used data type 'fvector' which stands for 'vector of floats' (in our case this will be only 2 elements but that is still a vector) for inputs and 'fscalar' for expected output.\n",
    "\n",
    "Now let's define our internal parameters (aka weights). Please not that we provide initial values to the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = theano.shared(numpy.asarray([0.2, 0.7]), 'W')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the three \"functions\" we had before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (x * W).sum()\n",
    "\n",
    "cost = theano.tensor.sqr(target - y)\n",
    "\n",
    "gradients = theano.tensor.grad(cost, [W])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how elegant this is using symbolic notation? In particular the gradient function, it accepts the cost function and a list of Theano variables representing weights. Here we only have one set of weights but soon when we introduce multi-layered models, this list will become much longer.\n",
    "\n",
    "Now we need to define the way we will be updating the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_updated = W - LEARNING_RATE * gradients[0]\n",
    "updates = [(W, W_updated)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list that contains weights to be updated. Each element on the list consists of a pair: a Theano variable representing weights and an expression that represents how they should be updated.\n",
    "\n",
    "Finally we can compile our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = theano.function([x, target], [y, W], updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First argument is a list of input variables. To perform an update we need to provide examples: inputs and expected outputs. Second argument represents the output from a function, in this case we are interested in knowing current output of the function as well as current weights. Third argument is the updates which tell how weights should be updated.\n",
    "\n",
    "Now all we need to do is run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output before update 1 is 0.55\n",
      "Output before update 2 is 29.7250011593\n",
      "Output before update 3 is 15.1374988407\n",
      "Output before update 4 is 22.4312508695\n",
      "Output before update 5 is 18.7843744203\n",
      "Output before update 6 is 20.6078128623\n",
      "Output before update 7 is 19.6960935326\n",
      "Output before update 8 is 20.1519532518\n",
      "Output before update 9 is 19.924023365\n",
      "Output before update 10 is 20.037988322\n",
      "Output before update 11 is 19.9810058367\n",
      "Final weights values: w1: 15.744804669385768 w2: 8.472402334692886\n"
     ]
    }
   ],
   "source": [
    "for update in range(NUM_UPDATES + 1):\n",
    "    y, w = f([1.0, 0.5], 20.0)\n",
    "    print \"Output before update {} is {}\".format(update + 1, y)\n",
    "print \"Final weights values: w1: {} w2: {}\".format(w[0], w[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the result is nearly identical to our result from previous lesson. Because values returned by our Theano function \"f\" are calculated before applying updates, we did one update more to get comparable output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
